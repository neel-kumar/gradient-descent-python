{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use gradient descent to fit a line to a set of randomly generated points using PyTorch and GPU\n",
    "\n",
    "from __future__ import print_function\n",
    "import random\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-efficients of a straight line\n",
    "a_org = 5\n",
    "b_org = 3\n",
    "\n",
    "# Start of the line\n",
    "x_start = 0\n",
    "\n",
    "# End of the line\n",
    "x_end = 10\n",
    "\n",
    "# How far away the points can be from the line on the y axis\n",
    "pm = 10\n",
    "\n",
    "# How many points\n",
    "n = 1000\n",
    "\n",
    "# The range of randomly generated x axis values\n",
    "x_min = 0\n",
    "x_max = 10\n",
    "\n",
    "# Error limit\n",
    "err_limit = 0.1\n",
    "\n",
    "# Learning Rate\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randint(x_min, x_max, n)\n",
    "py = x * a_org + b_org\n",
    "y = py - np.random.randint(-pm, pm, n)\n",
    "# x, py, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gen_scatter(a, b, n, pm, x_min, x_max):\n",
    "    x_array = torch.FloatTensor(n).random_(x_min, x_max)\n",
    "    py = a * x_array + b\n",
    "    y_array = py - torch.FloatTensor(n).random_(-pm, pm)\n",
    "    return x_array, y_array\n",
    "\n",
    "def err(a, b, x_array, y_array):\n",
    "    y = a * x_array + b\n",
    "    return ((y - y_array) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_slope_err(x_array, y_array, a, b):\n",
    "    y = a * x_array + b\n",
    "    avg_a_err = (2 * (y - y_array) * x_array).mean()\n",
    "    avg_b_err = (2 * (y - y_array)).mean()\n",
    "    return [avg_a_err, avg_b_err] \n",
    "#a, b = avg_slope_err(x_array, y_array, a_org, b_org)\n",
    "#a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# dev = torch.device(\"cpu\")\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(33.5940, device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_array, y_array = gen_scatter(a_org, b_org, n, pm, x_min, x_max)\n",
    "x_array = x_array.to(dev)\n",
    "y_array = y_array.to(dev)\n",
    "e = err(a_org, b_org, x_array, y_array)\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring the variables for gradient decent\n",
    "gd_a = torch.tensor(random.randint(-x_max, x_max), dtype = torch.float, requires_grad =  True, device=dev)\n",
    "gd_b = torch.tensor(random.random(), dtype = torch.float, requires_grad =  True, device=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Time at the start of gd is 2019-05-25 09:11:56.412867. gd_a = 4.0. gd_b = 0.9433304071426392\n",
      "The Time at iteration # 10000 of gd is 2019-05-25 09:11:59.248062 gd_a 4.943131446838379 gd_b 3.658792734146118 err 33.40387725830078.\n",
      "The Time at iteration # 20000 of gd is 2019-05-25 09:12:02.091701 gd_a 4.94173002243042 gd_b 3.667710304260254 err 33.40385055541992.\n",
      "The Time at iteration # 30000 of gd is 2019-05-25 09:12:05.097747 gd_a 4.94173002243042 gd_b 3.667710304260254 err 33.40385055541992.\n",
      "The Time at iteration # 40000 of gd is 2019-05-25 09:12:07.879908 gd_a 4.94173002243042 gd_b 3.667710304260254 err 33.40385055541992.\n",
      "The Time at iteration # 50000 of gd is 2019-05-25 09:12:10.710759 gd_a 4.94173002243042 gd_b 3.667710304260254 err 33.40385055541992.\n",
      "The Time at iteration # 60000 of gd is 2019-05-25 09:12:13.537064 gd_a 4.94173002243042 gd_b 3.667710304260254 err 33.40385055541992.\n",
      "The Time at iteration # 70000 of gd is 2019-05-25 09:12:16.390752 gd_a 4.94173002243042 gd_b 3.667710304260254 err 33.40385055541992.\n",
      "The Time at iteration # 80000 of gd is 2019-05-25 09:12:19.107285 gd_a 4.94173002243042 gd_b 3.667710304260254 err 33.40385055541992.\n",
      "The Time at iteration # 90000 of gd is 2019-05-25 09:12:21.896556 gd_a 4.94173002243042 gd_b 3.667710304260254 err 33.40385055541992.\n",
      "The Time at iteration # 100000 of gd is 2019-05-25 09:12:24.790581 gd_a 4.94173002243042 gd_b 3.667710304260254 err 33.40385055541992.\n",
      "The Time at the end of gd is 2019-05-25 09:12:24.790819. gd_a = 4.94173002243042. gd_b = 3.667710304260254\n",
      "The original a is 5 and the original b is 3. The error for these values are 33.59400177001953\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "max_i = 100000\n",
    "\n",
    "print (\"The Time at the start of gd is {}. gd_a = {}. gd_b = {}\".format(datetime.now(), gd_a, gd_b))\n",
    "\n",
    "# This is the part of the program that does gradient decent\n",
    "while (i < max_i):\n",
    "    i = i + 1\n",
    "    \n",
    "    loss = err(gd_a, gd_b, x_array, y_array)\n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        gd_a -= gd_a.grad * lr\n",
    "        gd_b -= gd_b.grad * lr        \n",
    "        gd_a.grad.zero_()\n",
    "        gd_b.grad.zero_()\n",
    "\n",
    "    # ase = avg_slope_err(x_array,y_array, gd_a, gd_b)\n",
    "    # This utilizes the avg_slpoe_err function))\n",
    "    # gd_a = gd_a - ase[0] * lr\n",
    "    # gd_b = gd_b - ase[1] * lr\n",
    "    \n",
    "    if i % 10000 == 0:\n",
    "        print (\"The Time at iteration # {} of gd is {} gd_a {} gd_b {} err {}.\".format(i, datetime.now(), gd_a, gd_b, err(gd_a, gd_b, x_array, y_array)))\n",
    "\n",
    "print (\"The Time at the end of gd is {}. gd_a = {}. gd_b = {}\".format(datetime.now(), gd_a, gd_b))\n",
    "\n",
    "print (\"The original a is {} and the original b is {}. The error for these values are {}\".format(a_org, b_org, err(a_org, b_org, x_array, y_array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
